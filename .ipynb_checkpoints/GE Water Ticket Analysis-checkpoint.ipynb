{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#  <div align='center'> Ticket Analysis and guess SLA compliance </div>\n",
    "\n",
    "> The code is to Analyse the tickets from customer and build the mode to guess is the SLA was met for a set of input provided or not  \n",
    "\n",
    "Last Update: 28-Feb-2017\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "# Algorithms \n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "# Other tools for model training and accuracy check\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "GE_Tkts = pandas.read_csv(\"GEW Inc1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The columns we'll use to predict the target\n",
    " \n",
    "# predictors = [\"Grp Code\", \"Cat Code\", \"Sub Cat code\", \"Priority Code\"]\n",
    "\n",
    "predictors = [ \"Cat Code\", \"Sub Cat code\", \"Priority Code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize our algorithm class\n",
    "# alg = tree.DecisionTreeClassifier(min_samples_split=2, criterion=\"entropy\", max_features = \"auto\")  # Around 72.81%\n",
    "# alg = tree.DecisionTreeClassifier()  # Around 72.62%\n",
    "# alg = SVC(C=2.0, kernel = \"rbf\") #kernel = \"rbf\" resulted = 73% \n",
    "# alg =  GaussianNB()\n",
    "# alg =  BernoulliNB()\n",
    "# alg = KNeighborsClassifier(algorithm=\"ball_tree\", weights = \"distance\") #Around 71.8%\n",
    "# alg = LinearRegression()\n",
    "# alg = Lasso(alpha = .01)\n",
    "# alg = AdaBoostClassifier(n_estimators = 3000) ## Acc = 72.42\n",
    "# alg = GradientBoostingClassifier(n_estimators = 4000)\n",
    "alg = RandomForestClassifier(criterion = \"entropy\")  #Best accuracy of 73.39%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div align= \"center\"> Analysis of accuracy with different parameters </div>\n",
    "\n",
    "+ Working with SVC\n",
    "> __Kernel = rbf__ ..\n",
    "> Does good job with accuracy score of 72.02%. \n",
    "> When removed the predictor Grp Code, it improved to __72.62%__\n",
    "> <br> *kernel* = poly took long time to complete and did not come back.\n",
    "> <br> parameter value *C*=2 bumped the accuracy score from 72.62% to __73%__. Default C value is 1 (accu=72.02%)\n",
    "> <br> Stack xchange [link]( http://stats.stackexchange.com/questions/31066/what-is-the-influence-of-c-in-svms-with-linear-kernel) about effect of value *C* in SVMs. Basically what should be the margin set during fitting. \n",
    "> <br> More detailed info is in [Sklearn documentation](http://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html)\n",
    "> <br> I tried many values, Default *gamma* was doing better job, \n",
    "+ Decision Trees\n",
    "> Decition tree with default value resulted accuracy = 72.62%\n",
    "> <br> with *min_samples_split*=2, *criterion*=\"entropy\", *max_features* = \"auto\" -> Accuracy increased to = __72.81%__\n",
    "+ KNeighborsClassifier\n",
    "> Parameters = *algorithm*=\"auto\", *weights* = \"distance\". \n",
    "> With an accuracy of 71.84%\n",
    "> <br> When removed the Grp Code as predictor - it atuall decreased to 71.26%. \n",
    "> As far of *algorithm* parameter is concerned, auto and kd_tree has the same results while ball_tree reduced the accuracy a bit\n",
    "+ Gaussian Naive Bayes\n",
    "> This with default values performed poorly with accuracy of 67.76%\n",
    "+ AdaBoost Classifier and GradientBoostingClassifier\n",
    "> Default accuracy = 70.29%\n",
    "> <br> with parameter *n_estimators* the accuracy impacted a lot. With the value *n_estimators* = 3000, the accuracy boosted to __72.42%__\n",
    "> GradientBoost the accuracy was 72.23% with *n_estimators* = 4000\n",
    "+ RandomForestClassifier\n",
    "> With just default value this gave acc = 72.81%\n",
    "> <br> Changed the *criterian* = \"entropy\" and *max_features* = None it gave the best result of accuracy __73.98%__\n",
    "> <br> **Note** Everytime I ran this algorithm keeps changing the accuracy, may be because of randomness. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate cross validation folds for dataset.  It return the row indices corresponding to train and test.\n",
    "# We set random_state to ensure we get the same splits every time we run this.\n",
    "\n",
    "GE_Tkts_data = GE_Tkts[predictors]\n",
    "GE_Tkts_targets = GE_Tkts[\"SLA Met\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.726213592233\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "#for train, test in kf:\n",
    "# The predictors we're using the train the algorithm.  Note how we only take the rows in the train folds.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(GE_Tkts_data, GE_Tkts_targets, test_size=0.1, random_state=0)\n",
    "\n",
    "# Training the algorithm using the predictors and target.\n",
    "alg.fit(X_train, y_train)\n",
    "# We can now make predictions on the test fold\n",
    "test_predictions = alg.predict(X_test)\n",
    "print(alg.score(X_test,y_test))\n",
    "\n",
    "# i = 0\n",
    "# sum = 0.00\n",
    "# for SLA in y_test:\n",
    "#     diff = age - test_predictions[i]\n",
    "# #     print(diff, age, test_predictions[i])\n",
    "#     sum = sum + np.square(diff)\n",
    "#     i = i + 1\n",
    "# avg = sum / y_test.shape[0]\n",
    "# deviation = np.sqrt(avg)\n",
    "# print(deviation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat Code          8\n",
      "Sub Cat code     60\n",
      "Priority Code     3\n",
      "Name: 13, dtype: int64\n",
      "Predicted Value [1]\n",
      "Actual Value 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karthik.sunil\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:395: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# X1_test = [[10,70,2]]\n",
    "# print(alg.predict(X1_test))\n",
    "\n",
    "index = 13\n",
    "print(GE_Tkts_data.iloc[index])\n",
    "test_predictions = alg.predict(GE_Tkts_data.iloc[index])\n",
    "\n",
    "# test_predictions = alg.predict(X1_test)\n",
    "\n",
    "print(\"Predicted Value\", test_predictions)\n",
    "print(\"Actual Value\", GE_Tkts_targets.iloc[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
